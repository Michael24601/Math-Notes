


\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}

\input{../../variables.tex}

\title{%
    \Huge Numerical Algorithms \\
    \Large Lecture XI, XII
}
\date{2025-05-26}
\author{Michael Saba}

\begin{document}
\pagenumbering{gobble}
\maketitle
\newpage
\setlength{\parindent}{0pt}
\pagenumbering{arabic}

\subsection*{Monte-Carlo Integration}

In the last lecture, we mentioned that
we can design our change of variable transformations
such that certain terms, like $\cos$
or $\sin$, cancel out.
This is done for performance and simplicty
and numerical accuracy. \\

The idea of cancelling out terms from
an integral when changing variables
is that we have an integral:
\[ \int g(x)h(x) dx \]
Where $h(x)$ is nearly flat (near its average
value), so integrating it with Monte-Carlo
only requires a couple samples. \\
So if we eliminate $g(x)$ using the above method,
we could easily do Monte-Carlo. \\

Suppose we want to cancel out a term 
$g(x)$. \\
Then we can note that by the Fundamental
Theorem of Calculus, if:
\[ g(x) = \int P(x) dx \]
then $|\det(J_P)| = g(x)$. \\
We know that:
\[ \det(J_{P\inv}) =  \det(J_{P}\inv)
= \dfrac{1}{\det(J_{P})}
= \dfrac{1}{g(x)} \]
So in order to cancel out a term $g(x)$,
we would want to have the term
$|J_{P\inv}|$ after our change of variables. \\

So we want some transformation $P$ such that:
\[ J_{P} = g(x) \cdot c \]
for some constant $c$. 
We can find $P$ using the anti-derivative. \\
This leads us to $J_{P\inv}$, which
will cancel out the term $g(x)$,
and leaves a constant. \\

Why do we need a constant? \\
The transform that yields $|J_{P\inv}|$
must have variable range at $[0, 1]^d$
so our range is a unit hypercube.
This constraint can be used to set $c$. \\
Note that this transformation is done 
after the initial transformation into a 
unit hypercube. \\
If we have $x \in [a, b]$ in the original
integral, we want that $P(a) = 0$
and $P(b) = 1$,
which is to say:
\[ G(x) = \dfrac{P(x) - P(a)}{P(x) - P(b)} \]
where $G(x)$ is our transformation
whose inverse keeps the variables 
in $[0, 1]$. \\

Note that this makes the second transformation
redundant, where we turn rectangular
interval into a square (linear map).
This transformation eliminates the
noisy term, and turns the variable range
into a unit hypercube, so there is no need
for that linear map. \\

Note that we will actually have a double
integral over $\phi$ and $\theta$,
but only $\theta$ is in the $\cos$
and $\sin$ term, so we functionally
have a single integral. \\
We still need a linear map to map $\varphi$
to $[0, 1]$. \\
So we combine the two in one transform. \\

We do have to assume $g(x)$ is non-negative,
since we have an absolute value around the
determinant $|J_{P\inv}|$. \\

If we have:
\[ \int_0^{2\pi}|\sin(\theta)|d\theta \]
then we divide the interval:
\[ \int_0^{\pi} \sin(\theta) d\theta 
+ \int_{\pi}^{2\pi} -\sin(\theta) d\theta\]
in this way. \\

We can drop the absolute value if we are
in an interval where the value is always
positive. \\

So all the steps: \\
First turn the integral into a Neumann
series without recursion. \\
Then turn each integral into a rectangular
coordinate space using parameterization. \\
Then do a map that gets rid of a noisy term
and turns the rectangle into a unit square/hypercube. \\

Be careful not to confuse the $\theta$
we get from parameterization,
and the special $\theta$
we get from $\omega_i \cdot n$,
the direction of the incident light. \\

Note that we often have to eliminate the
term $\cos^n(x)\sin(x)$,
where $\cos(x)\sin(x)$
the $n$ power comes from the BRDF. \\

This sampling method gets rid of the BRDF
and the $\cos$ and $\sin$ terms. \\

\newpage

\subsection*{Next Event Estimation}

If we have a very small light source, that is very
strong, we get a lot of noise; when it does
hit the light, which is rare, we get a lot of light. \\

So to solve this issue, we can directly send rays
onto the light source; on each bounce,
we can explicitely send a second ray onto
the light source. Usually we just pick one
random direction (Monte-Carlo with one sample).
But now we branch out, and have two rays
shoot out each time. \\

Note that this does not cause a tree,
since the ray that hits the light source
doesn't bounce further.
If we did bounce again, this would
become very inefficient. \\

The area formulatiom helps in this case,
since we can explicitely take a point on the
light source to where we want the ray
to hit. \\

So one of our rays will have the area formulation,
and the other uses solid angles.
We then combine the two at each bounce
each weighted by $w_0$ and $w_1$. \\

If we have multiple light sources,
we can at each point pick a random light
source to send a ray to (not all of them
at once). \\

The point on the light source we sample
must be random too. \\
Also note that we need the visibility used
here too to ensure nothing obstructs the
ray from the point on the light source. \\

Note that when choosing a point randomly
on the ligh source, we must also parametrize
and have some space $[0, 1]^d$. \\

NEE is is a special case of Multiple Important
Sampling:
\[ \int f(x)dx = \int 1 \cdot f(x) dx 
= \int w_1 f(x) dx + \int w_2 f(x) dx \]
Where $w_1 + w_2 = 1$. \\
In NEE, one of the pieces is the integral
on the light, and the other is the integral
for the normal ray bounce.
We can apply different changes of variables
for each part and get different estimators. \\
Note that we can have $n$ pieces,
not just $2$, but for NEE, we want just $2$,
one will be light sampling, the other will
be the normal bounce. \\

The only issue is that this will usually
cause having more calculations. \\

Note that having a point on the light's hemisphere
is enough to give us a direction (area formulation)
instead of the ray. This is better because we can
use the visibility function instead of using
the ray, which is more expensive when computing
intersections. The visibility function cares
not for normals, angles, etc... only visibility. \\

Note that there is a heuristic for the weights.
Once we do the change of variables and
get densities $p_i(x)$:
\[ w_1 = \dfrac{p_1(x)}{p_1(x) + p_2(x)} \]
\[ w_2 = \dfrac{p_2(x)}{p_1(x) + p_2(x)} \]
where $p_1(x)$ and $p_2(x)$ are the densities
inside the two integrals after the change
of variables. \\
The general heuristic is:
\[ w_1 = \dfrac{p_i(x)^n}{\sum_j^m p_j(x)^n} \]
The power is for the power heuristic. \\

Bidirectional path tracing:
Like in NEE, we want to sample the light directly.
But instead of sampling from light at each bounce
by shooting a ray onto the light, 
we trace a ray from the light first
onto a point, then connect it to path. \\

Light tracing is when we do the entire path
starting from light sources and then ending
up at the sensor; we avoid that because the
sensor is small. \\

We also talked a little about photon mapping. \\

Note that if we want to combine integrals,
it is always best to have the same measure
(both solid angles or both area formulation). \\
Note that the visibility is only used with
area formulation. \\

Note that NEE always fails with mirrors, 
because mirrors always reflect in just one
direction the light, so light coming from some
other ray is not contributing as per the BRDF. \\

\newpage

\subsection*{Probability}

The probability of an outcome is the number
of favorable outcomes divided by the
number of all outcomes $\Omega$. \\

In a continuous space, like a hemisphere,
the same applied, we just use measures
(like the area).
So the probability of an outcome
is the area of the space of all points
in teh outcome over the total area
(assuming all points have an equal probability). \\

We should normalize the probabilties by the
total measure (area) of the total space;
this is because $P(\Omega)$ must be $1$. \\

The probability of one point in the continuous
setting is 0. Doesn't mean it's impposible,
it's just that the likelihood is impossible. \\

The expected value of some random variable
$f(X)$ is the average or mean:
\[ E(f(X)) = \dfrac{1}{N}\sum_i^N P(x_i)f(x_i) \]
And in the continuous one:
\[ E(f(X)) = \int_\Omega p(x_i)f(x_i) dx \]
where $p(x_i)$ is the density function.
This is not the probability, but the integral is:
\[P(x \in A) = \int_A p(x)dx \]

We also have variance of a random variable
$f(X)$, which is:
\[ \var(f(X)) = E((f(X) - E(f(X))^2)) \]
This tell us how much the data varies. \\

This is where the $\dfrac{1}{N}$ error
comes from in our convergence of the Monte-Carlo
estimator (by taking the variance
of a sum of identically distirbuted but
independent estimators averaged,
$\var(\dfrac{1}{N}\sum_i^N I_i)$). \\

Note that when we do change of variables:
\[ \int f(x) |\det(J_g)| dx \]
The term $|\det(J_g)|$ is basically our
density. \\

If we have an estimator $I_n$ for an integral $I$,
then the bias is:
\[ | E(I_n) - I | \]
Which tells us how far off it is.
As $N$ increases to infinity, we 
expect the bias to go to $0$. \\

Bias shows up as noise, or blur. \\

First we can derive the Monte-Carlo integration
method using these notions. \\
Suppose we have:
\[ I = \int_\Omega f(x)dx \]
Then we know that:
\[ I = \int_\Omega f(x) dx 
= \int_\Omega \dfrac{p(x)}{p(x)}f(x) dx  \]
So if we consider $p(x)$ to be the 
density of $x$, then we have:
\[ I = 
\int_\Omega \dfrac{p(x)}{p(x)}f(x) dx 
= E\para{\dfrac{f(x)}{p(x)}} \]
We can approximate the avergae:
\[ I \approx
\dfrac{1}{N}\sum_i^N\dfrac{f(x_i)}{p(x_i)} \]
And since we assume we will be sampling points
uniformally in our ray tracer, we assume that the
density is uniform, so:
\[ I \approx
\dfrac{1}{N}\sum_i^N\dfrac{f(x_i)}{\alpha} \]
\[ I \approx
\dfrac{\sfrac{1}{\alpha}}{N}\sum_i^N f(x_i) \]
Notice that this is the same estimator we got before,
where $\dfrac{1}{\alpha}$ is the measure of the interval
(this makes sense since the density of a uniform
distribution is 1 over the interval). \\

Now suppose we do some change of variables,
same as before, and get the integral:
\[ I = \int_{[0, 1]^d} f(T(u)) |\det(J_T)|du  \]
Where the estimator is:
\[ I \approx \dfrac{|\det(J_T)|}{N}\sum_i^N f(u_i) \]
Notice that if we assume that $u_i$
is uniformally distributed, then
\[ \alpha = \dfrac{1}{|\det(J_T)|} \]
is the density function of $x$.
This makes sense; when we change variables from
$x$ to $u$, where $u$ is uniformally
sampled from a unit hypercube,
the interval changes size, and the way 
samples $x$ are generated 
depends on the transform and the 
way the interval changes. \\

So the inverse of the terms we get
when we change variables will be the density
of the generated points. \\
Here $f(x)$ is basically the BRDF,
and visbility... \\

So we can think of the change of variables
as changing the density of the points $x$,
and how we generate the points
(in such a way that we have a uniform
distirbution in the unit hypercube).
In that sense, the generated determinants
of Jacobians give us the density. \\

So this is how we will get the density
of $x$, which we will use in our heuristic 
$w_1$ and $w_2$. \\

\newpage

\subsection*{Change of Variables}

When we wanted to get rid of
$\cos(\theta)\sin(\theta)$,
this only depends on one variable, so
we only have a single integral (the integral
over $\phi$ we can ignore). \\

But what if we had some function $p(\theta, \phi)$,
that depends on them both, or more than $2$? \\

We would have to find a single map for each 
coordinate, such that the determinant of the Jacobian
cancels out $p(\theta, \phi)$. \\

Notice that when we have:
\[ I = \int f(\theta, \phi)p(\theta, \phi) 
\; d\theta d\phi \]
We can treat $p(\theta, \phi)$
like the density function, and decompose it
into $p(\theta) \cdot p(\phi \mid \theta)$. \\
So we then use individual
maps for $\theta$ and $\phi$
based on cancelling each of the marginal
and conditional. \\

However, in order for $p(x)$
to truly be a density function, we need:
\[ \int p(x)dx = 1 \]
We can ensure that by normalizing it:
\[ p_{\text{new}}(x) = \dfrac{p(x)}{\int p(x) dx} \]
Which ensure that $p_{\text{new}}$
is the density of $x$. \\ 

This allows us to then get rid of the term,
and sample $\theta$ and $\phi$ without
its weight. \\

\end{document}
